{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samuel_cahyawijaya/anaconda2/envs/py36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models\n",
    "import h5py\n",
    "import json\n",
    "\n",
    "from preprocessing import *\n",
    "from crowdnet_pytorch import CrowdNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'cc_epoch_15.mdl'\n",
    "model_path = os.path.expanduser(os.path.join('./models/demo_dcc_crowdnet', model_name))\n",
    "dataset_path = 'dataset/UCF_CC_50/'\n",
    "shanghai_train_path = 'dataset/ShanghaiTech/Train/'\n",
    "shanghai_test_path = 'dataset/ShanghaiTech/Test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/UCF_CC_50/37.json\n",
      "dataset/UCF_CC_50/20.json\n",
      "dataset/UCF_CC_50/20.json 62.50520805512529 637.2357512953367 (<class 'IndexError'>, IndexError('index 637 is out of bounds for axis 1 with size 600',), <traceback object at 0x7f596e2a9f88>)\n",
      "dataset/UCF_CC_50/36.json\n",
      "dataset/UCF_CC_50/8.json\n",
      "dataset/UCF_CC_50/3.json\n",
      "dataset/UCF_CC_50/15.json\n",
      "dataset/UCF_CC_50/43.json\n",
      "dataset/UCF_CC_50/19.json\n",
      "dataset/UCF_CC_50/41.json\n",
      "dataset/UCF_CC_50/26.json\n",
      "dataset/UCF_CC_50/47.json\n",
      "dataset/UCF_CC_50/34.json\n",
      "dataset/UCF_CC_50/11.json\n",
      "dataset/UCF_CC_50/44.json\n",
      "dataset/UCF_CC_50/1.json\n",
      "dataset/UCF_CC_50/1.json 149.34820247110426 984.2566389281416 (<class 'IndexError'>, IndexError('index 984 is out of bounds for axis 1 with size 984',), <traceback object at 0x7f596e2ab708>)\n",
      "dataset/UCF_CC_50/1.json 533.5036428856122 984.2566389281419 (<class 'IndexError'>, IndexError('index 984 is out of bounds for axis 1 with size 984',), <traceback object at 0x7f596e2ab708>)\n",
      "dataset/UCF_CC_50/5.json\n",
      "dataset/UCF_CC_50/ 16 img loaded\n",
      "dataset/UCF_CC_50/ 16 den loaded\n"
     ]
    }
   ],
   "source": [
    "images, gts, gts_count, densities = load_images_and_gts(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CrowdNet()\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "# if torch.cuda.is_available():\n",
    "#     model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3, 768, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(images[0].reshape(1, images[0].shape[2], images[0].shape[0], -1).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_count = []\n",
    "for i in range(len(images)):\n",
    "    input_img = Variable(torch.Tensor(images[i].reshape(1, images[i].shape[2], images[i].shape[0], -1)))\n",
    "#     if torch.cuda.is_available():\n",
    "#         input_img.cuda()\n",
    "\n",
    "    predicted = model(input_img)\n",
    "    predicted_count.append(predicted.data.sum().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_and_gts_shanghai(path):\n",
    "    images = []\n",
    "    gts = []\n",
    "    gts_count = []\n",
    "    densities = []\n",
    "    for gt_file in glob.iglob(os.path.join(path, '*.json')):\n",
    "        print(gt_file)\n",
    "        if os.path.isfile(gt_file.replace('.json','.png').replace('GT_','')):\n",
    "            img = cv2.imread(gt_file.replace('.json','.png').replace('GT_',''))\n",
    "        else:\n",
    "            img = cv2.imread(gt_file.replace('.json','.jpg').replace('GT_',''))\n",
    "        images.append(img)\n",
    "        \n",
    "        #load ground truth\n",
    "        gt, count = load_gt_from_json_shanghai(gt_file, img.shape[:-1])\n",
    "        gts.append(gt)\n",
    "        gts_count.append(count)\n",
    "        \n",
    "        #densities\n",
    "        desnity_file = gt_file.replace('.json','.h5')\n",
    "        if os.path.isfile(desnity_file):\n",
    "            #load density if exist\n",
    "            with h5py.File(desnity_file, 'r') as hf:\n",
    "                density = np.array(hf.get('density'))\n",
    "        else:\n",
    "            density = gaussian_filter_density([gt])[0]\n",
    "            with h5py.File(desnity_file, 'w') as hf:\n",
    "                hf['density'] = density\n",
    "        densities.append(density)\n",
    "    print(path, len(images), 'img loaded')\n",
    "    print(path, len(densities), 'den loaded')\n",
    "    return (images, gts, gts_count, densities)\n",
    "\n",
    "\n",
    "def load_gt_from_json_shanghai(gt_file, gt_shape):\n",
    "    gt = np.zeros(gt_shape, dtype='uint8') \n",
    "    with open(gt_file, 'r') as jf:\n",
    "        json_data = json.load(jf)\n",
    "        for j, dot in enumerate(json_data):\n",
    "            try:\n",
    "                gt[int(math.floor(dot['y'])), int(math.floor(dot['x']))] = 1\n",
    "            except IndexError:\n",
    "                print(gt_file, dot['y'], dot['x'], sys.exc_info())\n",
    "    return gt, len(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/ShanghaiTech/Train/GT_IMG_130.json\n",
      "dataset/ShanghaiTech/Train/GT_IMG_156.json\n",
      "dataset/ShanghaiTech/Train/GT_IMG_144.json\n",
      "dataset/ShanghaiTech/Train/GT_IMG_226.json\n",
      "dataset/ShanghaiTech/Train/GT_IMG_28.json\n",
      "dataset/ShanghaiTech/Train/GT_IMG_92.json\n",
      "dataset/ShanghaiTech/Train/GT_IMG_118.json\n",
      "dataset/ShanghaiTech/Train/GT_IMG_268.json\n",
      "dataset/ShanghaiTech/Train/GT_IMG_154.json\n",
      "dataset/ShanghaiTech/Train/GT_IMG_146.json\n",
      "dataset/ShanghaiTech/Train/GT_IMG_167.json\n",
      "dataset/ShanghaiTech/Train/GT_IMG_169.json\n",
      "dataset/ShanghaiTech/Train/GT_IMG_83.json\n",
      "dataset/ShanghaiTech/Train/GT_IMG_173.json\n",
      "dataset/ShanghaiTech/Train/GT_IMG_26.json\n",
      "dataset/ShanghaiTech/Train/GT_IMG_197.json\n",
      "dataset/ShanghaiTech/Train/GT_IMG_283.json\n",
      "dataset/ShanghaiTech/Train/GT_IMG_153.json\n",
      "dataset/ShanghaiTech/Train/GT_IMG_215.json\n",
      "dataset/ShanghaiTech/Train/GT_IMG_174.json\n",
      "dataset/ShanghaiTech/Train/ 20 img loaded\n",
      "dataset/ShanghaiTech/Train/ 20 den loaded\n"
     ]
    }
   ],
   "source": [
    "sh_tr_images, sh_tr_gts, sh_tr_gts_count, sh_tr_densities = load_images_and_gts_shanghai(shanghai_train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 0: Sizes of tensors must match except in dimension 1. Got 75 and 76 in dimension 2 at /opt/conda/conda-bld/pytorch_1524586445097/work/aten/src/TH/generic/THTensorMath.c:3586",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-53ff8e05df38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#         input_img.cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mpredicted_count_sh_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jupyter/crowd_counter/crowdnet_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeep_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mso\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshallow_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mco\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mso\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mco\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 0: Sizes of tensors must match except in dimension 1. Got 75 and 76 in dimension 2 at /opt/conda/conda-bld/pytorch_1524586445097/work/aten/src/TH/generic/THTensorMath.c:3586"
     ]
    }
   ],
   "source": [
    "predicted_count_sh_tr = []\n",
    "for i in range(len(sh_tr_images)):\n",
    "    input_img = Variable(torch.Tensor(sh_tr_images[i].reshape(1, sh_tr_images[i].shape[2], sh_tr_images[i].shape[0], -1)))\n",
    "#     if torch.cuda.is_available():\n",
    "#         input_img.cuda()\n",
    "\n",
    "    predicted = model(input_img)\n",
    "    predicted_count_sh_tr.append(predicted.data.sum().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/ShanghaiTech/Test/GT_IMG_104.json\n",
      "dataset/ShanghaiTech/Test/GT_IMG_130.json\n",
      "dataset/ShanghaiTech/Test/GT_IMG_96.json\n",
      "dataset/ShanghaiTech/Test/GT_IMG_144.json\n",
      "dataset/ShanghaiTech/Test/GT_IMG_90.json\n",
      "dataset/ShanghaiTech/Test/GT_IMG_181.json\n",
      "dataset/ShanghaiTech/Test/GT_IMG_125.json\n",
      "dataset/ShanghaiTech/Test/GT_IMG_5.json\n",
      "dataset/ShanghaiTech/Test/GT_IMG_92.json\n",
      "dataset/ShanghaiTech/Test/GT_IMG_75.json\n",
      "dataset/ShanghaiTech/Test/GT_IMG_134.json\n",
      "dataset/ShanghaiTech/Test/GT_IMG_86.json\n",
      "dataset/ShanghaiTech/Test/GT_IMG_131.json\n",
      "dataset/ShanghaiTech/Test/GT_IMG_17.json\n",
      "dataset/ShanghaiTech/Test/GT_IMG_11.json\n",
      "dataset/ShanghaiTech/Test/GT_IMG_169.json\n",
      "dataset/ShanghaiTech/Test/GT_IMG_115.json\n",
      "dataset/ShanghaiTech/Test/GT_IMG_83.json\n",
      "dataset/ShanghaiTech/Test/GT_IMG_161.json\n",
      "dataset/ShanghaiTech/Test/GT_IMG_15.json\n",
      "dataset/ShanghaiTech/Test/GT_IMG_66.json\n",
      "dataset/ShanghaiTech/Test/GT_IMG_150.json\n",
      "dataset/ShanghaiTech/Test/GT_IMG_20.json\n",
      "dataset/ShanghaiTech/Test/GT_IMG_172.json\n",
      "dataset/ShanghaiTech/Test/GT_IMG_151.json\n",
      "dataset/ShanghaiTech/Test/ 25 img loaded\n",
      "dataset/ShanghaiTech/Test/ 25 den loaded\n"
     ]
    }
   ],
   "source": [
    "sh_ts_images, sh_ts_gts, sh_ts_gts_count, sh_ts_densities = load_images_and_gts_shanghai(shanghai_test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "invalid argument 0: Sizes of tensors must match except in dimension 1. Got 91 and 92 in dimension 3 at /opt/conda/conda-bld/pytorch_1524586445097/work/aten/src/TH/generic/THTensorMath.c:3586",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c9d584456666>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#         input_img.cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mpredicted_count_sh_ts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/jupyter/crowd_counter/crowdnet_pytorch.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mdo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeep_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mso\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshallow_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mco\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mso\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mco\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: invalid argument 0: Sizes of tensors must match except in dimension 1. Got 91 and 92 in dimension 3 at /opt/conda/conda-bld/pytorch_1524586445097/work/aten/src/TH/generic/THTensorMath.c:3586"
     ]
    }
   ],
   "source": [
    "predicted_count_sh_ts = []\n",
    "for i in range(len(sh_ts_images)):\n",
    "    input_img = Variable(torch.Tensor(sh_ts_images[i].reshape(1, sh_ts_images[i].shape[2], sh_ts_images[i].shape[0], -1)))\n",
    "#     if torch.cuda.is_available():\n",
    "#         input_img.cuda()\n",
    "\n",
    "    predicted = model(input_img)\n",
    "    predicted_count_sh_ts.append(predicted.data.sum().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-th 7356.0737 917 6439.07373046875\n",
      "1-th 2460.852 2706 -245.14794921875\n",
      "2-th 17070.873 2105 14965.873046875\n",
      "3-th 19059.918 1046 18013.91796875\n",
      "4-th 9336.03 2364 6972.0302734375\n",
      "5-th 5103.6646 1543 3560.66455078125\n",
      "6-th 6335.653 947 5388.65283203125\n",
      "7-th 1237.1349 754 483.1348876953125\n",
      "8-th 4477.3296 1284 3193.32958984375\n",
      "9-th 8969.056 2391 6578.0556640625\n",
      "10-th 3851.7375 1961 1890.737548828125\n",
      "11-th 10311.002 1115 9196.001953125\n",
      "12-th 8346.365 484 7862.365234375\n",
      "13-th 7596.233 2358 5238.23291015625\n",
      "14-th 12555.729 4633 7922.728515625\n",
      "15-th 3917.1382 469 3448.13818359375\n",
      "Total 127984.78894042969 27077 100907.78894042969 6306.7368087768555\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(predicted_count)):\n",
    "    print('{}-th'.format(i),predicted_count[i], gts_count[i], predicted_count[i] - gts_count[i])\n",
    "print('Total', sum(predicted_count), sum(gts_count), sum(predicted_count) - sum(gts_count), (sum(predicted_count) - sum(gts_count)) / len(predicted_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-th 5411.016 1177 4234.01611328125\n",
      "1-th 11655.305 728 10927.3046875\n",
      "2-th 24120.615 777 23343.615234375\n",
      "Total 41186.93603515625 18004 23182.93603515625 7727.645345052083\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(predicted_count_sh_tr)):\n",
    "    print('{}-th'.format(i),predicted_count_sh_tr[i], sh_tr_gts_count[i], predicted_count_sh_tr[i] - sh_tr_gts_count[i])\n",
    "print('Total', sum(predicted_count_sh_tr), sum(sh_tr_gts_count), sum(predicted_count_sh_tr) - sum(sh_tr_gts_count), (sum(predicted_count_sh_tr) - sum(sh_tr_gts_count)) / len(predicted_count_sh_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-th 8669.66 1175 7494.66015625\n",
      "1-th 5932.0894 921 5011.08935546875\n",
      "2-th 2010.1533 246 1764.1533203125\n",
      "3-th 8395.468 262 8133.4677734375\n",
      "4-th 6391.384 2256 4135.3837890625\n",
      "5-th 16875.645 216 16659.64453125\n",
      "6-th 13768.848 269 13499.84765625\n",
      "7-th 18455.596 817 17638.595703125\n",
      "8-th 17689.375 1366 16323.375\n",
      "9-th 4760.85 665 4095.85009765625\n",
      "10-th 9588.267 165 9423.2666015625\n",
      "11-th 13349.479 579 12770.478515625\n",
      "12-th 18411.209 604 17807.208984375\n",
      "13-th 6135.9077 1156 4979.90771484375\n",
      "14-th 11841.161 1068 10773.1611328125\n",
      "15-th 2714.4692 218 2496.46923828125\n",
      "16-th 1443.6036 1191 252.6036376953125\n",
      "17-th 23863.281 218 23645.28125\n",
      "18-th 1100.4116 266 834.41162109375\n",
      "19-th 5102.5713 341 4761.5712890625\n",
      "Total 196499.42736816406 18009 178490.42736816406 8924.521368408203\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(predicted_count_sh_ts)):\n",
    "    print('{}-th'.format(i),predicted_count_sh_ts[i], sh_ts_gts_count[i], predicted_count_sh_ts[i] - sh_ts_gts_count[i])\n",
    "print('Total', sum(predicted_count_sh_ts), sum(sh_ts_gts_count), sum(predicted_count_sh_ts) - sum(sh_ts_gts_count), (sum(predicted_count_sh_ts) - sum(sh_ts_gts_count)) / len(predicted_count_sh_ts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
